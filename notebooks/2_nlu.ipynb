{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40acbe1",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](\n",
    "https://colab.research.google.com/github/Simone-Alghisi/HMD-Lab/blob/master/notebooks/2_nlu.ipynb)\n",
    "\n",
    "On Colab:\n",
    "1. Switch to a GPU Runtime by clicking on *Runtime > Change runtime type > T4 GPU*\n",
    "2. Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930dae2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab only\n",
    "!git clone https://github.com/Simone-Alghisi/HMD-Lab.git\n",
    "%cd /content/HMD-Lab/notebooks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed2f7ab",
   "metadata": {},
   "source": [
    "![system_architecture](./assets/system.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d303704",
   "metadata": {},
   "source": [
    "# Natural Language Understanding (NLU)\n",
    "\n",
    "Natural Language Understanding (NLU) is the component that, given a user's free-text utterance, performs Slot Filling (extracting the corresponding value) and Intent Classification.\n",
    "\n",
    "- *Intent* — a coarse surrogate of the meaning of the sentence that. In the Amazon Alexa's Framework: \"A representation of the action that fulfills a customer's spoken request\". Examples: \n",
    "  - `pizza_ordering`\n",
    "  - `drink_ordering`\n",
    "  - `out_of_domain`\n",
    "  - ...\n",
    "- *Slots* — a set of parameters that are required to fulfill an intent. Examples for `pizza_ordering`: \n",
    "  - `pizza_size`\n",
    "  - `pizza_type`\n",
    "  - `pizza_count`\n",
    "  - ...\n",
    "- *Values* — the set of valid attributes for a slot (slot: value). Examples: \n",
    "  - `pizza_size`: `medium`\n",
    "  - `pizza_type`: `margherita`\n",
    "  - `pizza_count`: `2`\n",
    "  - ...\n",
    "\n",
    "Why this matters:\n",
    "- The intent tells the system what to do next (e.g., collect order details vs. provide a menu).\n",
    "- Slots capture the pieces of information you need to complete the intent (e.g., size, type, quantity).\n",
    "- Missing Values are used by the system to understand which Slots are required to fulfill an intent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da60d8c0",
   "metadata": {},
   "source": [
    "## Question\n",
    "\n",
    "You want to design an OrderBot to collect the user's pizza order.\n",
    "\n",
    "Consider the following sentence: *\"I'd like a medium margherita pizza, please.\"*\n",
    "\n",
    "1. What is the intent?\n",
    "2. What are the values in the user request?\n",
    "3. Which slots are missing from the user request to fulfill its intent?\n",
    "\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"intent\": \"\",\n",
    "  \"slots\": {\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290a3a17",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954fc011",
   "metadata": {},
   "source": [
    "Consider the following sentence: *\"I'd like a medium margherita pizza, please.\"*\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"intent\": \"pizza_ordering\",\n",
    "  \"slots\": {\n",
    "    \"pizza_size\": \"medium\",\n",
    "    \"pizza_type\": \"margherita\",\n",
    "    \"pizza_count\": null\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a95898",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e9e8eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simone/miniconda3/envs/hmd/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.97it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import MODELS\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name, InitModel, prepare_text = MODELS[\"qwen3\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = InitModel(\n",
    "    model_name,\n",
    "    dtype=\"auto\",\n",
    "    device_map=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f70882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from notebooks.notebook_utils import display_conversation\n",
    "from models.qwen3 import prepare_text\n",
    "\n",
    "task_prompt = \"\"\"Identify the user intent from this list: \n",
    "[pizza_ordering, drink_ordering, out_of_domain].\n",
    "\n",
    "If the intent is pizza_ordering, extract the following slot values from the user input\n",
    "- pizza_size, the size of the pizza\n",
    "- pizza_type, the type of pizza\n",
    "- pizza_count, the number of pizzas as a numeric value.\n",
    "If no values are present in the user input you have to put 'null' as value.\n",
    "\n",
    "Only output the json object without any additional text.\n",
    "The json format is: \n",
    "{\n",
    "    \"intent\": \"...\", \n",
    "    \"slots\": {\n",
    "        \"slot\": \"value\"\n",
    "    }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86034039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Conversation\n",
       "\n",
       "**System:** Identify the user intent from this list: \n",
       "[pizza_ordering, drink_ordering, out_of_domain].\n",
       "\n",
       "If the intent is pizza_ordering, extract the following slot values from the user input\n",
       "- pizza_size, the size of the pizza\n",
       "- pizza_type, the type of pizza\n",
       "- pizza_count, the number of pizzas as a numeric value.\n",
       "If no values are present in the user input you have to put 'null' as value.\n",
       "\n",
       "Only output the json object without any additional text.\n",
       "The json format is: \n",
       "{\n",
       "    \"intent\": \"...\", \n",
       "    \"slots\": {\n",
       "        \"slot\": \"value\"\n",
       "    }\n",
       "}\n",
       "\n",
       "**User:** I would like a medium margherita pizza, please.\n",
       "\n",
       "**Assistant:** {\n",
       "    \"intent\": \"pizza_ordering\",\n",
       "    \"slots\": {\n",
       "        \"pizza_size\": \"medium\",\n",
       "        \"pizza_type\": \"margherita\",\n",
       "        \"pizza_count\": \"1\"\n",
       "    }\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "user_message = \"I would like a medium margherita pizza, please.\"\n",
    "\n",
    "zero_shot = [\n",
    "    {\n",
    "        \"role\": \"system\", \n",
    "        \"content\": task_prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "text = prepare_text(user_message, tokenizer, zero_shot)\n",
    "\n",
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=16384).cpu()\n",
    "\n",
    "# decode the output\n",
    "output_ids = generated_ids[0][len(model_inputs.input_ids[0]) :].tolist()\n",
    "content = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "display_conversation(zero_shot, user_message, content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5525146f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": \"pizza_ordering\",\n",
      "  \"slots\": {\n",
      "    \"pizza_size\": \"medium\",\n",
      "    \"pizza_type\": \"margherita\",\n",
      "    \"pizza_count\": \"1\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(json.loads(content), ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86909bb4",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Extend the following prompt to handle other intents:\n",
    "- `out_of_domain`\n",
    "- `drink_ordering`\n",
    "\n",
    "For each intent, specify the (optional) slots that may be required to fulfill it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e361d30",
   "metadata": {},
   "source": [
    "# Dialogue State Tracking (DST)\n",
    "\n",
    "The Dialogue State Tracker (DST) updates the Dialogue State (DS) based on the current turn.\n",
    "\n",
    "The dialogue state contains information about the intent and its extracted (or missing) slot-value pairs.\n",
    "\n",
    "Through the DS, the system has a summary (abstract meaning representation) of the dialogue (better than relying on the WHOLE dialogue history).\n",
    "\n",
    "The dialogue state is passed among components, and allows the system to track which slots are still missing (null) so the Dialog Manager (DM) can ask follow-ups.\n",
    "\n",
    "DST responsibilities:\n",
    "- Merge new NLU outputs with the existing state.\n",
    "- Keep canonical, normalized slot values (e.g., \"medium\" not \"Medium \")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d907bf2",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Suppost the current DS is:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"intent\": \"pizza_ordering\", \n",
    "    \"slots\": {\n",
    "        \"pizza_type\": null,\n",
    "        \"pizza_size\": \"medium\",\n",
    "        \"pizza_count\": null\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "What do you expect to happen if the next user's utterance is *\"I would like a margherita?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7091d89",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f86b9a8",
   "metadata": {},
   "source": [
    "We have a new value for `pizza_type`, so we update our DS accordingly\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"intent\": \"pizza_ordering\", \n",
    "    \"slots\": {\n",
    "        \"pizza_type\": \"margherita\",\n",
    "        \"pizza_size\": \"medium\",\n",
    "        \"pizza_count\": null\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63087716",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eee349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def clean_response(response: dict) -> dict:\n",
    "    \"\"\"Clean an NLU response for safe merging into the dialogue state.\"\"\"\n",
    "    def _clean(obj):\n",
    "        if isinstance(obj, dict):\n",
    "            out = {}\n",
    "            for k, v in obj.items():\n",
    "                # Normalize explicit textual nulls\n",
    "                if isinstance(v, str) and v.strip().lower() == \"null\":\n",
    "                    v = None\n",
    "                if v is None:\n",
    "                    continue\n",
    "                if isinstance(v, dict):\n",
    "                    cleaned = _clean(v)\n",
    "                    if cleaned:\n",
    "                        out[k] = cleaned\n",
    "                else:\n",
    "                    out[k] = v\n",
    "            return out\n",
    "        else:\n",
    "            return obj\n",
    "\n",
    "    return _clean(deepcopy(response))\n",
    "\n",
    "\n",
    "\n",
    "def update_ds(ds: dict, nlu_response: dict) -> dict:\n",
    "    \"\"\"Merge a cleaned NLU response into the dialogue state `ds`.\"\"\"\n",
    "    for key, value in nlu_response.items():\n",
    "        if value is None:\n",
    "            continue\n",
    "        # If the incoming value is a dict (commonly 'slots'), merge recursively\n",
    "        if isinstance(value, dict):\n",
    "            if key not in ds or not isinstance(ds.get(key), dict):\n",
    "                ds[key] = {}\n",
    "            for subk, subv in value.items():\n",
    "                if subv is None:\n",
    "                    continue\n",
    "                ds[key][subk] = subv\n",
    "        else:\n",
    "            ds[key] = value\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ea6903",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_response = \"\"\"{\n",
    "    \"intent\": \"pizza_ordering\", \n",
    "    \"slots\": {\n",
    "        \"pizza_type\": \"margherita\",\n",
    "        \"pizza_size\": null,\n",
    "        \"pizza_count\": null\n",
    "    }\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38168539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dialogue state BEFORE update:\n",
      "{\n",
      "  \"intent\": \"pizza_ordering\",\n",
      "  \"slots\": {\n",
      "    \"pizza_type\": null,\n",
      "    \"pizza_size\": \"medium\",\n",
      "    \"pizza_count\": null\n",
      "  }\n",
      "}\n",
      "\n",
      "Dialogue state AFTER update:\n",
      "{\n",
      "  \"intent\": \"pizza_ordering\",\n",
      "  \"slots\": {\n",
      "    \"pizza_type\": \"margherita\",\n",
      "    \"pizza_size\": \"medium\",\n",
      "    \"pizza_count\": null\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Initial dialogue state (previous context)\n",
    "dialogue_state = {\n",
    "    \"intent\": \"pizza_ordering\",\n",
    "    \"slots\": {\n",
    "        \"pizza_type\": None,\n",
    "        \"pizza_size\": \"medium\",\n",
    "        \"pizza_count\": None\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Dialogue state BEFORE update:\")\n",
    "print(json.dumps(dialogue_state, ensure_ascii=False, indent=2))\n",
    "\n",
    "parsed = json.loads(nlu_response)\n",
    "cleaned = clean_response(parsed)\n",
    "\n",
    "# Merge into dialogue state\n",
    "updated_state = update_ds(dialogue_state, cleaned)\n",
    "print(\"\\nDialogue state AFTER update:\")\n",
    "print(json.dumps(updated_state, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56bd8eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing slots: ['pizza_count']\n"
     ]
    }
   ],
   "source": [
    "# Example: what the dialog manager should now ask next\n",
    "missing_slots = [k for k, v in updated_state.get(\"slots\", {}).items() if v is None]\n",
    "print(\"\\nMissing slots:\", missing_slots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7082326",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "You are given:\n",
    "- a sentence\n",
    "- the ground-truth intent and slot-value pairs\n",
    "\n",
    "Question: *How can we evalute the NLU component?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600d8d6",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "Sentence: *\"I would like a margherita pizza\"*\n",
    " \n",
    "Ground-Truth:\n",
    "```json\n",
    "{\n",
    "    \"intent\": \"pizza_ordering\", \n",
    "    \"slots\": {\n",
    "        \"pizza_type\": \"margherita\",\n",
    "        \"pizza_size\": null,\n",
    "        \"pizza_count\": null\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "How can we use this information to evaluate our NLU component?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deb130a",
   "metadata": {},
   "source": [
    "#### Solution\n",
    "We expect that a proper NLU model will correctly\n",
    "1. classify the intent\n",
    "2. fill the slots using the right values\n",
    "\n",
    "By comparing the **ground-truth** with the **prediction** from the NLU, we can compute metrics such as the overall Intent and Slot *F1-Score* and *Accuracy*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f6da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Tuple, Any\n",
    "\n",
    "def _normalize_val(v: Any):\n",
    "    \"\"\"Normalize slot values for comparison.\"\"\"\n",
    "    if isinstance(v, str) and v.strip().lower() == \"null\":\n",
    "        return None\n",
    "    if v is None:\n",
    "        return None\n",
    "    # try to normalize numeric strings to int\n",
    "    if isinstance(v, str):\n",
    "        s = v.strip()\n",
    "        if s.isdigit():\n",
    "            return int(s)\n",
    "        try:\n",
    "            f = float(s)\n",
    "            return f\n",
    "        except Exception:\n",
    "            return s.lower()\n",
    "    if isinstance(v, (int, float)):\n",
    "        return v\n",
    "    return v\n",
    "\n",
    "def _equal_slot(a: Any, b: Any) -> bool:\n",
    "    a_n = _normalize_val(a)\n",
    "    b_n = _normalize_val(b)\n",
    "    return a_n == b_n\n",
    "\n",
    "def evaluate_nlu(pred_states: List[Dict], gt_states: List[Dict]) -> Dict:\n",
    "    \"\"\"\n",
    "    Evaluate NLU predictions against ground-truth dialogue states.\n",
    "\n",
    "    Args:\n",
    "      pred_states: list of predicted dialogue states, each like {\"intent\": \"...\", \"slots\": {...}}\n",
    "      gt_states:   list of ground-truth dialogue states, same format\n",
    "\n",
    "    Returns:\n",
    "      Dictionary with:\n",
    "        - intent_accuracy: fraction of examples with correct intent\n",
    "        - slot_accuracy: fraction of slot values correct (computed over all GT slots)\n",
    "    \"\"\"\n",
    "    if len(pred_states) != len(gt_states):\n",
    "        raise ValueError(\"pred_states and gt_states must have the same length\")\n",
    "\n",
    "    n = len(gt_states)\n",
    "    if n == 0:\n",
    "        return {\"intent_accuracy\": 0.0, \"slot_accuracy\": 0.0}\n",
    "\n",
    "    intent_correct = 0\n",
    "    total_slots = 0\n",
    "    correct_slots = 0\n",
    "\n",
    "    for pred, gt in zip(pred_states, gt_states):\n",
    "        # intents\n",
    "        if pred.get(\"intent\") == gt.get(\"intent\"):\n",
    "            intent_correct += 1\n",
    "\n",
    "        gt_slots = gt.get(\"slots\", {}) or {}\n",
    "        pred_slots = pred.get(\"slots\", {}) or {}\n",
    "\n",
    "        for slot_name, gt_val in gt_slots.items():\n",
    "            total_slots += 1\n",
    "            # predicted might miss the slot key -> treat as None\n",
    "            pred_val = pred_slots.get(slot_name, None)\n",
    "            if _equal_slot(pred_val, gt_val):\n",
    "                correct_slots += 1\n",
    "\n",
    "    return {\n",
    "        \"intent_accuracy\": intent_correct / n,\n",
    "        \"slot_accuracy\": (correct_slots / total_slots) if total_slots else 0.0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01bb4aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent_accuracy': 1.0, 'slot_accuracy': 0.6666666666666666}\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "preds = [\n",
    "    {\n",
    "        \"intent\": \"pizza_ordering\",\n",
    "        \"slots\": {\n",
    "            \"pizza_size\": \"medium\",\n",
    "            \"pizza_type\": \"margherita\",\n",
    "            \"pizza_count\": None,\n",
    "        },\n",
    "    }\n",
    "]\n",
    "gts = [\n",
    "    {\n",
    "        \"intent\": \"pizza_ordering\",\n",
    "        \"slots\": {\"pizza_size\": \"medium\", \"pizza_type\": None, \"pizza_count\": None},\n",
    "    }\n",
    "]\n",
    "print(evaluate_nlu(preds, gts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf970c",
   "metadata": {},
   "source": [
    "Sometimes, Per-Intent and Per-Slot F1-Score and Accuracy may be more informative, since they can provide additional details about the model shortcomings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
